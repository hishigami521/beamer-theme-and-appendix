\begin{frame}<1>
  \setbeamercovered{transparent}
  \frametitle{Chapter 6}

  \begin{block}{Chapter 6の内容}
    \begin{enumerate}[Sec.~6.1]
    \item GKLR法
    \item 本論文におけるGKLR法の実装
      \begin{itemize}
      \item 停止条件の設計
      \item 2分法+逆反復法の部分特異対計算への適用
      \end{itemize}
    \item 再直交化計算アルゴリズム
      \begin{itemize}
      \item CGS2法
      \item[\checkmark] OMP-CGS2法        
      \end{itemize}
    \item 共有メモリ型マルチコア計算機上での数値実験による性能評価
    \item OMP-CGS2法のデータ再利用についての考察
    \end{enumerate}
    \end{block}

  \begin{enumerate}[{[{A}1]}]
    \footnotesize
    \setcounter{enumi}{2}
  \item M, Takata, \textbf{H. Ishigami}, K. Kimura, Y. Fujii, H. Tanaka, and Y. Nakamura,
  ``Performance evaluation of Golub-Kahan-Lanczos algorithm with reorthogonalization by classical Gram-Schmidt algorithm and OpenMP,''
    {\em IPSJ Transactions on Mathematical Modeling and Its Applications}, accepted. 
  \end{enumerate}
\end{frame}

\begin{frame}
  \frametitle{再直交化付きGKL法}
  \begin{block}{再直交化付きGKL法（GKLR法）}
    \begin{itemize}
    \item 2つのKrylov部分空間に基づく反復法
      \begin{align*}
        \small
        \mathcal{K}_k(M^\top M,\ \bm{b}) & = \operatorname{span}\left\{ \bm{b},\ \left(M^\top M \right) \bm{b},\ \dots,\ \left(M^\top M \right)^{k-1} \bm{b} \right\} \\
	\mathcal{K}_k(MM^\top,\ M\bm{b}) & = \operatorname{span}\left\{ M\bm{b},\ \left(MM^\top\right) M\bm{b},\ \dots,\ \left(MM^\top\right)^{k-1} M\bm{b} \right\}
      \end{align*}
    \item Krylov部分空間のベクトルの直交性を保つため、再直交化を加える
      \begin{itemize}
      \item 計算量: $O({k_{\textrm{end}}}^2(m+n))$
      \end{itemize}
    \item 再直交化計算がボトルネックとなりうる
    \end{itemize}
  \end{block}
  \input{rgkl_highlight_en.tex}
\end{frame}

\begin{frame}
  \frametitle{再直交化付きGKL法 (GKLR法)}
    \begin{minipage}{.6\hsize}
      \begin{exampleblock}{\small Alg.~GKLR法}
	\algrenewcommand\alglinenumber[1]{\scriptsize ####1:}
	\begin{algorithmic}[1]
	  \scriptsize
	  \State Set an $n$-dimensional unit vector $\bm{p}_1$
	  \State $\bm{q}=M\bm{p}_1,\ \alpha_1=\|\bm{q}\|_2,\ \bm{q}_1=\bm{q}/\alpha_1$
	  \State $\textcolor{red}{\alpha_1} = \| \tilde{\bm{q}}_1 \|$, $\bm{q}_1 = \tilde{\bm{q}}_1 / \alpha_1$
	  \State $P_1=[\bm{p}_1],Q_1=[\bm{q}_1]$
	  \Do{$k=1,\ 2,\ \dots$}
	  \State $\bm{p} = M^\top \bm{q}_k$
	  \State \fcolorbox{ForestGreen}{ForestGreen!20}{$\tilde{\bm{p}} = \operatorname{Reorthogonalization}( P_k,\ \bm{p} )$}
	  \State $\beta_k=\pm \| \tilde{\bm{p}} \|_2$, $\bm{p}_{k+1} = \tilde{\bm{p}} / \beta_k$
	  \State Check the singular values of $B_{k}$
	  \State $\bm{q} = M \bm{p}_{k+1}$
	  \State \fcolorbox{ForestGreen}{ForestGreen!20}{$\tilde{\bm{q}} = \operatorname{Reorthogonalization}( Q_k,\ \bm{q} )$}
	  \label{line:gklr-reorth-u}
	  \State $\alpha_{k+1} = \pm\| \tilde{\bm{q}} \|_2$, $\bm{q}_{k+1}=\tilde{\bm{q}} / \alpha_{k+1}$
	  \State $P_{k+1} = \begin{bmatrix} P_k & \bm{p}_{k+1} \end{bmatrix}$, 
	  $Q_{k+1} = \begin{bmatrix} Q_k & \bm{q}_{k+1} \end{bmatrix}$
	  \EndDo
	\end{algorithmic}
      \end{exampleblock}
    \end{minipage}
    \hfill
    \begin{minipage}{.38\hsize}
      \small
      \begin{itemize}
      \item $B_k \in \mathbb{R}^{k \times k}$:
	\begin{align*}
	  B_k & = 
	  \begin{bmatrix}
	    \textcolor{red}{\alpha_1} \\
	    \textcolor{blue}{\beta_1} & \textcolor{red}{\alpha_2} \\
	    & \ddots & \ddots \\
	    && \textcolor{blue}{\beta_{k-1}} & \textcolor{red}{\alpha_k}
	  \end{bmatrix}
	\end{align*}
      %% \item $B_k$ becomes larger \par as $k$ increases
      \end{itemize}
    \end{minipage}

    \begin{itemize}
      %% \item GKLR accomplishes with very small $k$ ($\ll \min(m,n)$)
    \item 各行の計算内（BLAS中心）で並列化
    \item[\checkmark] 再直交化計算がボトルネック $\to$ 新たな並列アルゴリズムの提案
  %% \item \textcolor{blue}{Bottleneck w.r.t. elapsed time}: \textcolor{red}{Reorthogonalization process} 
  \end{itemize}

\end{frame}

%% \begin{frame}
%%   \frametitle{Computational cost of GKLR algorithm}
%%   \begin{block}{Computational cost of GKLR algorithm}
%%     \begin{itemize}
%%     \item Computaional cost: 
%%       \begin{center}
%%         \begin{tabular}{lcc} \hline
%%           & each iter. & total \\\hline\hline
%% 	  Sparse Mat-Vec &  $O(e_{\textrm{nzc}})$ & $O(k_{\textrm{end}}e_{\textrm{nzc}})$ \\
%% 	  Reorthogonalization & $O(k(m+n))$ & $O(k_{\textrm{end}}^2(m+n))$ \\\hline
%%         \end{tabular}
%%       \end{center}
%%       \begin{itemize}
%%       \item $k_{\textrm{end}}$: \# of iteration at the point when GKLR alg. stops
%%       \item $e_{\textrm{nzc}}$: \# of non-zero elements of a sparse matrix $M \in \mathbb{R}^{m \times n}$
%%       \end{itemize}
%%     \item $k_{\textrm{end}}$ becomes larger as $\ell$ is large ($\ell$: \# of required singular triplets)\par
%%       $\Rightarrow$ \textcolor{red}{Reorth. process becomes the bottleneck w.r.t. elapsed time}
%%     \end{itemize}
%%   \end{block}
%%   \pause
%%   \begin{alertblock}{Contents of this work}
%%     \begin{itemize}
%%     \item Goal: Accelerate GKLR algorithm
%%     \item[\checkmark] Develop faster parallel reorthogonalization algorithm
%%     \end{itemize}
%%   \end{alertblock}
%% \end{frame}

\begin{frame}
  \frametitle{再直交化アルゴリズム}

  \begin{block}{従来の再直交化アルゴリズム}
    \begin{itemize}
    \item Gram-Schmidt (GS) type
      \begin{itemize}
      \item \textcolor{blue}{MGS}法 (BLAS 1)
      \item 古典GS (CGS) 法 (BLAS 2)
      \item \textcolor{red}{CGS2法} (BLAS 2)
      \end{itemize}
    \item Householder type
      \begin{itemize}
      \item Householder 再直交化法 (BLAS 1)
      \item \textcolor{blue}{compact WY 再直交化法 (cWY)} (BLAS 2) [Yamamoto-Hirota, 2011]
      \end{itemize}
    \end{itemize}
  \end{block}

  \begin{alertblock}{Remark: 従来の再直交化アルゴリズムの並列化}
    \begin{itemize}
    \item 従来の再直交化アルゴリズム: 並列BLASによる並列化
    \item BLAS 1 または、BLAS 2
    \end{itemize}
  \end{alertblock}
  \begin{itemize}
  \item[\checkmark] \underline{並列BLASに頼らない}、効率の良い並列アルゴリズムを提案
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{CGS法およびCGS2法}

    \begin{itemize}
    \item $\bm{a}_i \in \mathbb{R}^n$の再直交化: \\
      $\bm{x}_1,\ \dots,\ \bm{x}_{i-1}$に直交なベクトル$\bm{x}_i$に変換する ($1 \le i \le m,\ m \le n$)
    \end{itemize}
  \begin{block}{CGS法による$\bm{a}_i$の再直交化計算}
      \begin{align*}
	\bm{x}_i = \bm{a}_i - \sum_{k=1}^{i-1} \langle \bm{x}_k, \bm{a}_i \rangle \bm{x}_k
      \end{align*}
  \end{block}
  
  \begin{itemize}
  \item 現代では、行列乗算を用いたCGS法が一般的: 
    \begin{align*}
      & \bm{x}_i = \bm{a}_i - X_{i-1} X_{i-1}^\top \bm{a}_i, \\
      & X_{i-1} = \begin{bmatrix} \bm{x}_1 & \cdots & \bm{x}_{i-1} \end{bmatrix}
    \end{align*}
  \end{itemize}

  \begin{itemize}
  \item CGS algorithm with reorthogonalization (\textcolor{red}{CGS2法})
    \begin{itemize}
    \item CGS法で得られるベクトルは、直交性が悪い場合がある
    \item[\checkmark] 直交性を高めるため, \textcolor{blue}{CGS法を2回繰り返す}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Alternative parallel implementation of CGS algorithm}
  \begin{block}{CGS法による$\bm{a}_i$の再直交化計算}
      \begin{align*}
	\bm{x}_i = \bm{a}_i - \sum_{k=1}^{i-1} \langle \bm{x}_k, \bm{a}_i \rangle \bm{x}_k
      \end{align*}
      \begin{itemize}
      \item[\checkmark] 総和計算について、並列性を抽出することができる
      \end{itemize}
  \end{block}
  
  \begin{itemize}
  \item 総和計算 ($\Sigma$, $k$についての\textbf{do}-ループ)の並列化を考える
    \begin{itemize}
    \item スレッド並列化では、\textcolor{red}{OpenMP}で実装できる
      \begin{itemize}
      \item 実装上では、配列リダクションが必要 $\to$ Fortranなら``\texttt{reduction}''
      \item \textcolor{blue}{並列BLASに頼らない}実装となる
      \end{itemize}
    \item[\checkmark] 計算量は、元のCGS法と同じ
    \end{itemize}
  \end{itemize}
  %
\end{frame}

\begin{frame}<1-2>
  \frametitle{提案手法: OpenMPに基づくCGS法 (OMP-CGS法)}
  \alt<1>{
    \begin{exampleblock}{Alg.~CGS法 (BLAS 1)}
      \begin{algorithmic}[1]
	\Function{CGS}{$X_{i-1} (= [ \bm{x}_1,\ \dots,\ \bm{x}_{i-1} ])$, $\bm{a}_i$}
	\State $\bm{w} = \bm{a}_i$
	\Do{$k=1$ to $i-1$}
	\State $s = - \langle \bm{x}_k, \bm{w} \rangle$
	\State $\bm{a}_i = \bm{a}_i + s \bm{x}_k$
	\EndDo
	\State \Return $\bm{x}_i = \bm{a}_i$
	\EndFunction
      \end{algorithmic}
    \end{exampleblock}
  }{
  \begin{exampleblock}{Alg.~OMP-CGS法}
      \begin{algorithmic}[1]
	\Function{OMP-CGS}{$X_{i-1} (= [ \bm{x}_1,\ \dots,\ \bm{x}_{i-1} ])$, $\bm{a}_i$}
	\State $\bm{w} = \bm{a}_i$
	\State \textcolor{red}{\#omp parallel do private($s$) reduction(+:$\bm{a}_i$)}
	\Do{$k=1$ to $i-1$}
	\State $s = - \langle \bm{x}_k, \bm{w} \rangle$
	\State $\bm{a}_i = \bm{a}_i + s \bm{x}_k$
	\Comment \textcolor{blue}{Array reduction}
	\EndDo
	\State \textcolor{red}{\#omp end parallel do}
	\State \Return $\bm{x}_i = \bm{a}_i$
	\EndFunction
      \end{algorithmic}
    \end{exampleblock}
  }
  \pause
  \begin{alertblock}{提案実装の特徴}
    \begin{itemize}
    \item[\checkmark] データ再利用性が高い計算: $\bm{w},\ \bm{a}_i,\ \bm{x}_k$
    \item[\checkmark] Array reductionのときのみ同期が要される
    \end{itemize}
  \end{alertblock}
\end{frame}

\begin{frame}
  \frametitle{提案手法: OpenMPに基づくCGS2法 (OMP-CGS2法)}
  \begin{exampleblock}{Alg.~OMP-CGS2法}
    \begin{algorithmic}[1]
      \Function{OMP-CGS2}{$X_{i-1} (= [ \bm{x}_1,\ \dots,\ \bm{x}_{i-1} ])$, $\bm{a}_i$}
      \State \textcolor{red}{\texttt{\#omp parallel private($j,\ s$)}}
      \Do{$j=1,\ 2$}
      \State \textcolor{red}{\texttt{\#omp single}}
      \State $\bm{w} = \bm{a}_i$
      \Comment Perform serially
      %% \State \textcolor{red}{\texttt{\#omp end single}}
      \State \textcolor{red}{\texttt{\#omp do reduction(+:$\bm{a}_i$)}}
      \label{line:pcgs-for}
      \Do{$k=1$ to $i-1$}
      \State $s = - \langle \bm{x}_k,\ \bm{w} \rangle$
      \label{line:pcgs-dot}
      \State $\bm{a}_i = \bm{a}_i + s \bm{x}_k$
      \Comment Array reduction
      \label{line:pcgs-axpy}
      \EndDo
      %% \State \textcolor{red}{\texttt{\#omp end do}}
      \EndDo
      \State \textcolor{red}{\texttt{\#omp end parallel}}
      \State \Return $\bm{x}_i=\bm{a}_i$
      \EndFunction
    \end{algorithmic}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Theoretical performance of parallel reorthogonalization algs.}

  \begin{block}{Comparison of theoretical performance}
    \centering
    \begin{tabular}{lccc}
      & 計算量 & 直交性 & 主なBLAS\\\hline\hline
      MGS  & $2kn^2$ & $O(\epsilon\kappa(A))$ & L1 \\
      CGS2 & $4kn^2$ & $^\dagger O(\epsilon)$ & L2 \\
      cWY  & $4kn^2-n^3$ & $O(\epsilon)$ & L2 \\
      OMP-CGS2 & $4kn^2$ & $^\dagger O(\epsilon)$ & L1(serial) \\\hline
    \end{tabular}
  \end{block}
    \begin{itemize}
    \item 直交性: $\left\| X_k^\top X_k - I \right\|$
      \begin{itemize}
      \item $^\dagger$: CGS2法では、$\kappa(A)<1$が満たされている必要がある
      \end{itemize}
    \end{itemize}

\end{frame}

%%% Numerical experiment
\begin{frame}
  \frametitle{性能評価}
  \begin{block}{性能評価の内容}
    \begin{itemize}
    \item $\ell$組の特異対計算における\textcolor{red}{計算時間}と直交性を比較
      \begin{itemize}
      \item $\ell=100,\ 200,\ 400,\ 800$
      \item 最大特異値から$\ell$組
      \end{itemize}
    \end{itemize}
  \end{block}

  \begin{alertblock}{GKLR法のコード}
    \begin{itemize}
    \item 異なる4種の再直交化アルゴリズムを実装して比較:
      \begin{enumerate}
      \item GKLR with MGS
      \item GKLR with CGS2
      \item GKLR with cWY
      \item GKLR with OMP-CGS2 (提案実装)
      \end{enumerate}
    \item 各コードの再直交化計算の並列化:
      \begin{itemize}
      \item code 1-3: Intel MKLの並列BLASを適用
      \item code 4: OpenMPによる%よって\textbf{do}-ループを並列化
      \end{itemize}
    \end{itemize}
  \end{alertblock}
\end{frame}

\begin{frame}
  \frametitle{実験条件}
  \begin{block}{実験環境}
    \begin{itemize}
    \item Appro 2548X@京都大学学術情報メディアセンターの1ノード:
      \begin{itemize}
	\item CPU: Intel Xeon E5-4650L@2.6 GHz, 32 cores (8 cores $\times$ 4) 
        \item L3 cache: 20MB $\times$ 4 
	\item RAM DDR3-1066 1.5 TB, 136.4GB/sec 
	\item Compiler: Intel C++/Fortran Compiler 14.0.2 
	\item Options: \texttt{-O3 -xHOST -ipo -no-prec-div} \texttt{-openmp -mcmodel=medium -shared-intel}
	\item Software: Intel Math Kernel Library 11.1.2 
      \end{itemize}
    \end{itemize}
  \end{block}

%%     \begin{itemize}
%%     \item CPU: Intel Xeon E5-4650L @ 2.60GHz, 32 cores (8 cores $\times$ 4)
%%       \begin{itemize}
%%       \item L3 cache: 20MB $\times$ 4
%%       \end{itemize}
%%     \item RAM: DDR3-1066 1.5TB
%%     \item Compiler: Intel Fortran 14.0.2 / Intel C++ 14.0.2
%%       \begin{itemize}
%%       \item -O3 -xHOST -ipo-no-prec-div -mcmodel=medium -shared-intel -openmp
%%       \end{itemize}
%%     \item Library: Intel Math Kernel Library 11.1.2
%%     \end{itemize}
%%   \end{block}

  \begin{alertblock}{その他の条件}
    \begin{itemize}
    \item 32スレッドで実行
    \item テスト行列: ランダムで非対称な疎行列、非零要素は$(0,1]$の一様乱数  
      \begin{itemize}
      \item $T_1$: $16,000 \times 8,000$, $T_2$: $32,000 \times 16,000$, $T_3$: $64,000 \times 32,000$
        \item $M_4$: $32,000 \times 32,000$ Frank行列
      \end{itemize}
    \end{itemize}
  \end{alertblock}

\end{frame}

\begin{frame}
  \frametitle{計算時間の比較}
  \begin{minipage}{.49\textwidth}
    \underline{Cases of $M_1$}
    {\centering\includegraphics[scale=.65]{./figure/src06/fig1a.pdf}}
    \begin{itemize}
    \item $\kappa(M_1) = 4.754\times 10^1$
    \item 反復回数:\par
      $\ell = 100$: $1,000$, 
      $\ell = 200$: $1,600$, \par
      $\ell = 400$: $2,400$, 
      $\ell = 800$: $4,000$
    \end{itemize}
  \end{minipage}
  \begin{minipage}{.49\textwidth}
    \underline{Cases of $M_2$}
    {\centering\includegraphics[scale=.65]{./figure/src06/fig1b.pdf}}
    \begin{itemize}
    \item $\kappa(M_2) = 4.803\times 10^1$
    \item 反復回数:\par
      $\ell = 100$: $1,300$,
      $\ell = 200$: $2,000$,\par
      $\ell = 400$: $3,200$, 
      $\ell = 800$: $4,800$
    \end{itemize}
  \end{minipage}
\end{frame}

\begin{frame}
  \frametitle{計算時間の比較}
  \begin{minipage}{.49\textwidth}
    \underline{Cases of $M_3$: }
    {\centering\includegraphics[scale=.65]{./figure/src06/fig1c.pdf}}
    \begin{itemize}
      \item $\kappa(M_3) = 4.757\times 10^1$
      \item 反復回数:\par
      $\ell = 100$: $1,600$,
      $\ell = 200$: $2,400$,\par
      $\ell = 400$: $3,600$, 
      $\ell = 800$: $5,600$
    \end{itemize}
  \end{minipage}
  \begin{minipage}{.49\textwidth}
    \underline{Cases of $M_4$:}
    {\centering \includegraphics[scale=.65]{./figure/src06/fig1d.pdf}}
    \begin{itemize}
      \item $\kappa(M_4) =1.600\times 10^9$
      \item 反復回数:\par
      $\ell = 100$: $200$,  
      $\ell = 200$: $400$, \par
      $\ell = 400$: $800$,
      $\ell = 800$: $1,600$
    \end{itemize}
  \end{minipage}
\end{frame}
  
%% \begin{frame}
%%   \frametitle{Re: (Proposed impl.) OpenMP-based parallel impl. of CGS}
%%   \begin{exampleblock}{Pseudocode of OMP-CGS (CGS by L1 BLAS+OpenMP)}
%%     \begin{algorithmic}[1]
%%       \Function{OMP-CGS}{$X_{i-1} (= [ \bm{x}_1,\ \dots,\ \bm{x}_{i-1} ])$, $\bm{a}_i$}
%%       \State $\bm{w} = \bm{a}_i$
%%       \State \textcolor{red}{\#omp parallel do private($s$) reduction(+:$\bm{a}_i$)}
%%       \Do{$k=1$ to $i-1$}
%%       \State $s = - \langle \bm{x}_k, \bm{w} \rangle$
%%       \State $\bm{a}_i = \bm{a}_i + s \bm{x}_k$
%%       \Comment \textcolor{blue}{Array reduction}
%%       \EndDo
%%       \State \textcolor{red}{\#omp end parallel do}
%%       \State \Return $\bm{x}_i = \bm{a}_i$
%%       \EndFunction
%%     \end{algorithmic}
%%   \end{exampleblock}
%% \end{frame}

%% \begin{frame}
%%   \frametitle{Model inequality for OMP-CGS2 alg.}
%%   \begin{itemize}
%%   \item If $\bm{a}_i$, $\bm{x}_k$, $\bm{w}$ on each threads are stored even in L3 cache on CPU, OMP-CGS2 alg. achieves higher performance!
%%     \begin{itemize}
%%     \item L3 cache of CPU has a limit \par
%%       $\Rightarrow$ Performance of OMP-CGS2 depends on size of vectors
%%     \end{itemize}
%%   \item Consider \textbf{do}-loop in terms of $k$...
%%     \begin{itemize}
%%     \item $\bm{w}$: shared by all of threads
%%     \item $\bm{a}_i$, $\bm{x}_k$: need the copies corresponding to each threads
%%     \end{itemize}
%%   \end{itemize}

%%   \begin{block}{Model inequality for OMP-CGS2 alg.}
%%     \begin{itemize}
%%     \item When OMP-CGS2 alg. achieves higher performance, \\ 
%%       $m$ (size of the vectors) must be satisfied the following inequality: 
%%       \textcolor{red}{
%%         \begin{align*}
%%           m \times (T\times 2+1) \times 8
%%           & \le
%%           C \times 1024 \times 1024
%%         \end{align*}
%%       }
%%       \begin{itemize}
%%       \item $T$: \# of threads
%%       \item $C$: size of L3 cache in CPU [MB]
%%       \end{itemize}
%%     \item[\checkmark] Under the condition of this work, $m \le 154202$ 
%%     \end{itemize}
%%     \end{block}
%% \end{frame}

\begin{frame}
  \frametitle{Chapter 6 のまとめ}
    \begin{itemize}
    \item （論文中）GKLR法に基づく大規模疎行列向け部分特異対計算において、2分法+逆反復法による部分固有値計算の適用について述べた
    \end{itemize}
    \begin{itemize}
    \item GKLR法のボトルネックである再直交化計算の高速化のため、OpenMPによる並列化を用いた新たなCGS2法（OMP-CGS2法）を提案し、数値実験により性能を評価した。
    \end{itemize}
    \begin{itemize}
    \item モデル式を立てることでOMP-CGS2法がCGS2法よりも高速である一条件を導き、その妥当性を数値実験により確認した
    \end{itemize}
\end{frame}
